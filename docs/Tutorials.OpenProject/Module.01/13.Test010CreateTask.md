# Test 010: UI - Create Task

:arrow_backward: [Previous](./12.Test009CreateProject.md) Unit 13 of 14 [Next](./14.Summary.md) :arrow_forward:

35 min · Unit · [Roei Sabag](https://www.linkedin.com/in/roei-sabag-247aa18/) · Level ★★☆☆☆
  
The test will verify that a new task with a random unique name was created under a work package according to data sent by the test.  

## Prerequisites

- [X] Change the `driver` value under `Manifest.json` file from `MockWebDriver` to `ChromeDriver`.
- [X] Change the `driverBinaries` value under `Manifest.json` from `.` to `http://selenoid:4444/wd/hub`.
- [X] You can access the application using a username and password. If you cannot, [please follow these instructions](./01.SetupOpenProjectApplication.md).
- [X] A project named `Demo Project` already exists. Follow [Setup Environment](../Tutorials.SetupEnvironment/00.Module.md) if it does not.

## Test Implementation

> :information_source: **Information**
>  
> The implementation of this test will be done in 7 phases.
>
> 1. Login to _**Open Project**_ application.
> 2. Find a work package under _**Demo Project**.
> 3. Save the total number of tasks under the work package.
> 4. Create a task under the work package.
> 5. Save the total number of tasks under the work package after the task was created.
> 6. Filter the task list to find the task we have created.

1. Right click on `TestCases` folder.
2. Select `New File`.  
3. Name your file `Test010CreateTask.rhino`.
4. Click on `Test010CreateTask.rhino` file to open it.  

![image 1.1 - New File Context Item](./Images/m01u13_1.png)  
_**image 1.1 - New File Context Item**_  

1. Type in the following test.  

```cmd
[test-id]         Test010
[test-scenario]   verify that task created when creating a task under an existing project
[test-priority]   1 - critical
[test-severity]   1 - critical
[test-tolerance]  0%

[test-actions]
/**
/** Login
1.  go to url {http://openproject}
2.  click on {//li[./a[.='Sign in']]}
3.  send keys {admin} into {//div[./label[.='Username']]//input[@type='text']}
4.  send keys {qawsedrf1!} into {//div[./label[.='Password']]//input[@type='password']}
5.  click on {//input[(@type='submit' or @type='button') and @value='Sign in']}
/**
/** Find Work Package
6.  click on {//li[./a[@id='projects-menu']]}
7.  send keys {{$ --keys:Demo project --interval:50}} into {project_autocompletion_input} by {id}
8.  click on {//li[@id='project-search-container']//li[.//a[.='Demo project']]}
9.  click on {//span[.='Work packages']/ancestor::a[@wp-query-menu]}
/**
/** Save Totals
10. register parameter {{$ --name:TasksBefore --scope:session}} take {//li[@class='pagination--range']/span[not(@id)]} with regex {(?<=\/)\d+(?=\)$)}
/**
/** Create a Task
11. register parameter {{$ --name:TaskName --scope:session}} take {Task _{{$guid}}_}
12. click on {//button[.='Create']}
13. click on {//ul[@role='menu']/li[.='Task']}
14. send keys {{$getparam --name:TaskName --scope:session}} into {//div[contains(@class,'new--subject')]//input}
15. click on {//button[.='Save']}
/**
/** Force Waiting for Creation Success
16. wait for element on {//notification//span[.='Successful creation.']}
/**
/** Save Totals
17. register parameter {{$ --name:TasksAfter --scope:session}} take {//li[@class='pagination--range']/span[not(@id)]} with regex {(?<=\/)\d+(?=\)$)}
/**
/** Filter
18. click on {//button[contains(.,'Filter')]}
19. send keys {{$ --keys:{{$getparam --name:TaskName --scope:session}} --interval:50}} into {//li[./label[.='Filter by text']]//input}
/**
/** Complete
20. close browser

[test-expected-results]
[5]  verify that {text} of {//li[./a/i]//op-principal/div} equal {OA}
[13] verify that {count} of {//editable-attribute-field//span[.='New' or .='Task']} equal {2}
[15] verify that {exists} status of {//editable-attribute-field//span[.='{{$getparam --name:TaskName}}']} equal {true}
[17] verify that {text} of {{$getparam --name:TasksAfter --scope:session}} is greater than {{$getparam --name:TasksBefore --scope:session}}
[19] verify that {exists} status of {//td/span[.='{{$getparam --name:TaskName --scope:session}}']} equal {true}
```  

## Run your Test

Rhino can run the test file directly from `Visual Studio Code`, by executing the invoke command.  

1. Open command palette by pressing `CTRL`+`SHIFT`+`P`.
2. Type `Rhino` to find Rhino Commands.
3. Select and run the command `Rhino: Runs the automation test(s) from the currently open document`.
4. A progress indication will show in `Visual Studio Code` status bar.  

![image 1.2 - Command Palette](./Images/m01u13_2.png)
_**image 1.2 - Command Palette**_  

When test invocation is complete, a report will be opened under a new `Visual Studio Code` tab.  

![image 1.3 - Rhino Report](./Images/m01u12_3.png)
_**image 1.3 - Rhino Report**_  

## Breakdown

### Test Metadata

The test metadata holds an important information about your test. There are many metadata fields and it can also use custom fields which are directly derived from your `Application Lifecycle Manager` (e.g., Jira, Azure DevOps, Test Rail, XRay, etc.).

| Field           | Meaning                                                                                                                                  |
|-----------------|------------------------------------------------------------------------------------------------------------------------------------------|
| test-id         | The unique identifier of the test. Please note the Rhino **will distinct** tests by their ID.                                            |
| test-scenario   | A statement describing the functionality to be tested.                                                                                   |
| test-categories | A comma separated list of categories (also refers as 'Tags' or 'Marks') to which this test belongs to.                                   |
| test-priority   | The level of **business importance** assigned to an item, e.g., defect.                                                                  |
| test-severity   | The degree of **impact** that a defect has on the development or operation of a component or system.                                     |
| test-tolerance  | The % of the test tolerance. A Special attribute to decide, based on configuration if the test will be marked as passed or with warning. |

### Test Actions

The numbers beside each action does not have any affect on the test itself and were designed to increase the test readability and to make it easier to assign expected results for each action based on the action positional location.  

**Actions (Plugins) Call:**  

1. `go to url` - Load _**Open Project**_ application in the current browser window. This is done using an HTTP GET operation and the method will block until the load is complete.
2. `click` - Clicks the mouse on the `Sign in` button.
3. `send keys` - Type `admin` into `Username` text-box under the `Sign in` panel.
4. `send keys` - Type `qawsedrf1!` into `Password` text-box under the `Sign in` panel.
5. `click` - Clicks the mouse on the `Sign in` button under the `Sign in` panel.
6. `click` - Clicks the mouse on the `Projects List` on the top left corner of the screen.
7. `send keys` - Type `Demo Project` into the `Search Project` text-box under the `Projects List` panel to find _**Demo Project**_.
8. `click` - Clicks the mouse on the `Demo Project` list-item in order to navigate to _**Demo Project**_ page.
9. `click` - Clicks the mouse on the `Work Packages` menu-item in order to open _**Demo Project**_ work packages page.
10. `register parameter` - Gets the total number of tasks and save it into `TasksBefore` session parameter.
11. `register parameter` - Creates a new, unique task name and save it into `TaskName` session parameter.
12. `click` - Clicks the mouse on the `Create` button on the top right corner of the screen.
13. `click` - Clicks the mouse on the `Task` list-item, under work package types list.
14. `send keys` - Type `TaskName` parameter value into `Subject` text-box under the `Create Task` panel.
15. `click` - Clicks the mouse on the `Save` button under `Create Task` panel.
16. `wait for element` - Waits for the success message to appear before continue to the next action.
17. `register parameter` - Gets the total number of tasks and save it into `TasksAfter` session parameter. This is the new number, after a new task was added.
18. `click` - Clicks the mouse on the `Filter` button under the top left corner of the screen.
19. `send keys` - Type the new task name into the `Filter by Text` text-box. The `interval` parameter says that between each character type, there will be a wait time of 50 milliseconds.
20. `close browser` - Close the browser session.

### Test Expected Results

The numbers beside each expected result points to the action it asserts based on the action positional under `[test-actions]` section. It is possible to point multiple assertions to the same action.  

**Actions (Plugins) Call:**  

1. `text` - Asserts that the inner-text of the user panel is `OA`, which means that the login was successful.
2. `count` - Asserts that the total elements that contains the work `New` and the word `Task` is `2`. This one actually verify that the title of the `Create Task` panel is `New Task`.
3. `exists` - Asserts that the name of the new task was applied to the title of the `Create Task` panel e,g. the name was changed from `New Task` to `Task <Task Name>`.
4. `text` - Asserts that the value (text) of `TasksAfter` is higher (greater) than `TasksBefore`. This one actually asserts that the new task is counted on the UI.
5. `exists` - Asserts that the new task can be found when filtering the tasks list e.g., the task is listed.

### Next Unit: "Test 010: UI - Create Task"

[Continue](./14.Summary.md) :arrow_forward:
